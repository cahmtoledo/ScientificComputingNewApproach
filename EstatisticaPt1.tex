\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{Inferencia bayesiana}
\author{Carmen Melo Toledo}
\date{January 2020}

\begin{document}

\maketitle

\section{Introduction}

\subsection{Probabilidade como crença}

Para tratarmos de inferência Bayesiana primeiro devemos constatar que se formos tratar matematicamente o quanto acreditamos em algo a probabilidade simula isso muito bem.
Por exemplo se temos uma sentença A, podemos dizer que P(A)=1 e P(~A)=0, com isso temos uma gama de valores intermediários. 
Também podemos dizer que se acreditamos em algo x, acreditamos no complementar com 1-x. E também podemos aferir uma propriedade transitiva para crenças, se acreditamos em A mais do que em B e em B mais do que em C, podemos afirmar que acreditamos em A mais do que em C.
A probabilidade consegue modelar essas exigências que fizemos, isso foi formalizado pelo matemático Richard Cox em 1946.

Com isso podemos atualizar nossas crenças frente a novas evidências usando o teorema de Bayes

\subsection{O teorema do aprendizado}

\begin{equation}
    P(H|\{D\},\theta) = \frac{P(\{D\}|H,\theta) P(H|\theta)}{P(\{D\}|\theta)}
\end{equation}

Para tratarmos isso como crenças, vamos dizer que H são as nossa hipóteses, \{D\} representa o conjunto de dados obtidos e $\theta$ representa nossas crenças prévias.

Assim $P(H|\theta)$ representa nosso conhecimento a priori do conjunto de hipóteses.
$P(\{D\}|H,\theta)$ é nossa verossimilhança, ou seja a probabilidade de se nossas hipóteses estiverem corretas observarmos os dados observados.
$P(\{D\}|\theta)$ é chamado de evidência, normalmente é usado como um fator de normalização e será melhor explorado mais para frente.
Por fim $ P(H|\{D\},\theta)$ é o conhecimento que temos a posteriori, depois de aprendemos com as evidências.

\section{Estudando uma moeda}

Suponha que um estranho, apareça e te mostre uma moeda e te pergunte qual a chance você acha de sair cara. A principio em geral o mais natural é você achar que é uma moeda comum, ou levemente enviesada posto que a maioria das moedas são comuns e é difícil de acreditar que um estranho forjou uma moeda por exemplo com duas caras.

Mas para facilitar podemos supor que o a priori seja que todas as hipóteses sobre a moeda sejam iguais. Nesse caso $P(H=h|\theta)=1, 0\leq h \leq 1$, sendo h a probabilidade de se sair cara. E obviamente essa função é zero em todos os outros lugares.

Dessa forma podemos aferir que nosso posterior vai ser proporcional a nossa verossimilhança. Ela dada por: $P(H|\{D\},\theta) \propto P(\{D\}|H,\theta)$

Então após N lançamentos, sendo R caras $P(\{D\}|H,\theta)=\binom{N}{R}h^{R}(1-h)^{(N-R)}$

Achando o valor de h que maximiza isso sabemos qual o resultado mais provável e também poderíamos desenhar um gráfico com todas as possibilidades

\end{document}
